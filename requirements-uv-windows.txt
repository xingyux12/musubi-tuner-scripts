# This file was autogenerated by uv via the following command:
#    uv pip compile .\requirements.txt -o requirements-uv.txt --index-strategy unsafe-best-match --no-build-isolation -p 3.10
absl-py==2.1.0
    # via tensorboard
accelerate==1.2.1
    # via -r ./requirements.txt
adam-mini==1.1.1
    # via -r ./requirements.txt
annotated-types==0.7.0
    # via pydantic
ascii-magic==2.3.0
    # via -r ./requirements.txt
av==14.0.1
    # via -r ./requirements.txt
bitsandbytes==0.45.0
    # via -r ./requirements.txt
certifi==2024.12.14
    # via
    #   requests
    #   sentry-sdk
charset-normalizer==3.4.1
    # via requests
click==8.1.8
    # via wandb
colorama==0.4.6
    # via
    #   ascii-magic
    #   click
    #   tqdm
contourpy==1.3.1
    # via matplotlib
cycler==0.12.1
    # via matplotlib
dadaptation==3.2
    # via -r ./requirements.txt
diffusers==0.32.1
    # via -r ./requirements.txt
docker-pycreds==0.4.0
    # via wandb
einops==0.7.0
    # via
    #   -r ./requirements.txt
    #   flash-attn
filelock==3.16.1
    # via
    #   diffusers
    #   huggingface-hub
    #   torch
    #   transformers
    #   triton
flash-attn @ https://github.com/sdbds/flash-attention-for-windows/releases/download/v2.7.3/flash_attn-2.7.3+cu124torch2.5.1-cp310-cp310-win_amd64.whl
    # via -r ./requirements.txt
fonttools==4.55.3
    # via matplotlib
fsspec==2024.12.0
    # via
    #   huggingface-hub
    #   torch
gitdb==4.0.12
    # via gitpython
gitpython==3.1.44
    # via wandb
grpcio==1.69.0
    # via tensorboard
heavyball==1.5.1
    # via -r ./requirements.txt
huggingface-hub==0.26.5
    # via
    #   -r ./requirements.txt
    #   accelerate
    #   diffusers
    #   tokenizers
    #   transformers
idna==3.10
    # via requests
importlib-metadata==8.5.0
    # via diffusers
jinja2==3.1.5
    # via torch
kiwisolver==1.4.8
    # via matplotlib
markdown==3.7
    # via tensorboard
markupsafe==3.0.2
    # via
    #   jinja2
    #   werkzeug
matplotlib==3.10.0
    # via -r ./requirements.txt
mpmath==1.3.0
    # via sympy
networkx==3.4.2
    # via torch
numpy==2.2.1
    # via
    #   accelerate
    #   bitsandbytes
    #   contourpy
    #   diffusers
    #   heavyball
    #   matplotlib
    #   opencv-python
    #   pytorch-optimizer
    #   tensorboard
    #   torchvision
    #   transformers
    #   xformers
opencv-python==4.10.0.84
    # via -r ./requirements.txt
opt-einsum==3.4.0
    # via heavyball
packaging==24.2
    # via
    #   accelerate
    #   huggingface-hub
    #   matplotlib
    #   tensorboard
    #   torch-optimi
    #   transformers
pillow==10.2.0
    # via
    #   -r ./requirements.txt
    #   ascii-magic
    #   diffusers
    #   matplotlib
    #   torchvision
pillow-avif-plugin==1.4.6
    # via -r ./requirements.txt
platformdirs==4.3.6
    # via wandb
prodigy-plus-schedule-free==1.8.51
    # via -r ./requirements.txt
prodigyopt==1.1.1
    # via -r ./requirements.txt
protobuf==5.29.3
    # via
    #   tensorboard
    #   wandb
psutil==6.1.1
    # via
    #   accelerate
    #   wandb
pydantic==2.10.5
    # via wandb
pydantic-core==2.27.2
    # via pydantic
pyparsing==3.2.1
    # via matplotlib
python-dateutil==2.9.0.post0
    # via matplotlib
pytorch-optimizer==3.3.2
    # via -r ./requirements.txt
pyyaml==6.0.2
    # via
    #   accelerate
    #   huggingface-hub
    #   transformers
    #   wandb
regex==2024.11.6
    # via
    #   diffusers
    #   transformers
requests==2.32.3
    # via
    #   diffusers
    #   huggingface-hub
    #   transformers
    #   wandb
safetensors==0.4.5
    # via
    #   -r ./requirements.txt
    #   accelerate
    #   diffusers
    #   transformers
sageattention @ https://github.com/sdbds/SageAttention-for-windows/releases/download/2.0.1_20250102/sageattention-2.0.1+cu124torch2.5.1-cp310-cp310-win_amd64.whl
    # via -r ./requirements.txt
schedulefree==1.4
    # via -r ./requirements.txt
sentry-sdk==2.19.2
    # via wandb
setproctitle==1.3.4
    # via wandb
setuptools==75.8.0
    # via
    #   tensorboard
    #   wandb
six==1.17.0
    # via
    #   docker-pycreds
    #   python-dateutil
    #   tensorboard
smmap==5.0.2
    # via gitdb
sympy==1.13.1
    # via torch
tensorboard==2.18.0
    # via -r ./requirements.txt
tensorboard-data-server==0.7.2
    # via tensorboard
tokenizers==0.20.3
    # via transformers
toml==0.10.2
    # via -r ./requirements.txt
torch==2.5.1+cu124
    # via
    #   -r ./requirements.txt
    #   accelerate
    #   bitsandbytes
    #   flash-attn
    #   heavyball
    #   prodigy-plus-schedule-free
    #   pytorch-optimizer
    #   torch-optimi
    #   torchvision
    #   xformers
torch-optimi==0.2.1
    # via -r ./requirements.txt
torchvision==0.20.1+cu124
    # via -r ./requirements.txt
tqdm==4.67.1
    # via
    #   -r ./requirements.txt
    #   huggingface-hub
    #   transformers
transformers==4.46.3
    # via -r ./requirements.txt
triton @ https://github.com/woct0rdho/triton-windows/releases/download/v3.1.0-windows.post5/triton-3.1.0-cp310-cp310-win_amd64.whl
    # via -r ./requirements.txt
typing-extensions==4.12.2
    # via
    #   bitsandbytes
    #   huggingface-hub
    #   pydantic
    #   pydantic-core
    #   torch
    #   wandb
urllib3==2.3.0
    # via
    #   requests
    #   sentry-sdk
voluptuous==0.15.2
    # via -r ./requirements.txt
wandb==0.19.2
    # via -r ./requirements.txt
werkzeug==3.1.3
    # via tensorboard
xformers==0.0.28.post3
    # via -r ./requirements.txt
zipp==3.21.0
    # via importlib-metadata
